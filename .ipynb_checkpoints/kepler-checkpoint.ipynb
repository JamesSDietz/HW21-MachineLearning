{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exoplanetary Machine Learning--Predicting Exoplanetary Status Using NASA Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### James Dietz\n",
    "### HW 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowid</th>\n",
       "      <th>kepid</th>\n",
       "      <th>disposition</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10797460</td>\n",
       "      <td>1</td>\n",
       "      <td>9.488036</td>\n",
       "      <td>170.538750</td>\n",
       "      <td>0.146</td>\n",
       "      <td>2.95750</td>\n",
       "      <td>616.0</td>\n",
       "      <td>2.26</td>\n",
       "      <td>793.0</td>\n",
       "      <td>93.59</td>\n",
       "      <td>35.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10797460</td>\n",
       "      <td>1</td>\n",
       "      <td>54.418383</td>\n",
       "      <td>162.513840</td>\n",
       "      <td>0.586</td>\n",
       "      <td>4.50700</td>\n",
       "      <td>875.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>443.0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>25.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>4.467</td>\n",
       "      <td>0.927</td>\n",
       "      <td>291.93423</td>\n",
       "      <td>48.141651</td>\n",
       "      <td>15.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10811496</td>\n",
       "      <td>0</td>\n",
       "      <td>19.899140</td>\n",
       "      <td>175.850252</td>\n",
       "      <td>0.969</td>\n",
       "      <td>1.78220</td>\n",
       "      <td>10800.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>638.0</td>\n",
       "      <td>39.30</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5853.0</td>\n",
       "      <td>4.544</td>\n",
       "      <td>0.868</td>\n",
       "      <td>297.00482</td>\n",
       "      <td>48.134129</td>\n",
       "      <td>15.436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10848459</td>\n",
       "      <td>0</td>\n",
       "      <td>1.736952</td>\n",
       "      <td>170.307565</td>\n",
       "      <td>1.276</td>\n",
       "      <td>2.40641</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>33.46</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>891.96</td>\n",
       "      <td>505.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5805.0</td>\n",
       "      <td>4.564</td>\n",
       "      <td>0.791</td>\n",
       "      <td>285.53461</td>\n",
       "      <td>48.285210</td>\n",
       "      <td>15.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10854555</td>\n",
       "      <td>1</td>\n",
       "      <td>2.525592</td>\n",
       "      <td>171.595550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.65450</td>\n",
       "      <td>603.0</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1406.0</td>\n",
       "      <td>926.16</td>\n",
       "      <td>40.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6031.0</td>\n",
       "      <td>4.438</td>\n",
       "      <td>1.046</td>\n",
       "      <td>288.75488</td>\n",
       "      <td>48.226200</td>\n",
       "      <td>15.509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowid     kepid  disposition  koi_period  koi_time0bk  koi_impact  \\\n",
       "0      1  10797460            1    9.488036   170.538750       0.146   \n",
       "1      2  10797460            1   54.418383   162.513840       0.586   \n",
       "2      3  10811496            0   19.899140   175.850252       0.969   \n",
       "3      4  10848459            0    1.736952   170.307565       1.276   \n",
       "4      5  10854555            1    2.525592   171.595550       0.701   \n",
       "\n",
       "   koi_duration  koi_depth  koi_prad  koi_teq  koi_insol  koi_model_snr  \\\n",
       "0       2.95750      616.0      2.26    793.0      93.59           35.8   \n",
       "1       4.50700      875.0      2.83    443.0       9.11           25.8   \n",
       "2       1.78220    10800.0     14.60    638.0      39.30           76.3   \n",
       "3       2.40641     8080.0     33.46   1395.0     891.96          505.6   \n",
       "4       1.65450      603.0      2.75   1406.0     926.16           40.9   \n",
       "\n",
       "   koi_tce_plnt_num  koi_steff  koi_slogg  koi_srad         ra        dec  \\\n",
       "0               1.0     5455.0      4.467     0.927  291.93423  48.141651   \n",
       "1               2.0     5455.0      4.467     0.927  291.93423  48.141651   \n",
       "2               1.0     5853.0      4.544     0.868  297.00482  48.134129   \n",
       "3               1.0     5805.0      4.564     0.791  285.53461  48.285210   \n",
       "4               1.0     6031.0      4.438     1.046  288.75488  48.226200   \n",
       "\n",
       "   koi_kepmag  \n",
       "0      15.347  \n",
       "1      15.347  \n",
       "2      15.436  \n",
       "3      15.597  \n",
       "4      15.509  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kepler = pd.read_csv(\"kepler.csv\")\n",
    "kepler.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kepler.drop(['rowid', 'kepid'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disposition           int64\n",
       "koi_period          float64\n",
       "koi_time0bk         float64\n",
       "koi_impact          float64\n",
       "koi_duration        float64\n",
       "koi_depth           float64\n",
       "koi_prad            float64\n",
       "koi_teq             float64\n",
       "koi_insol           float64\n",
       "koi_model_snr       float64\n",
       "koi_tce_plnt_num    float64\n",
       "koi_steff           float64\n",
       "koi_slogg           float64\n",
       "koi_srad            float64\n",
       "ra                  float64\n",
       "dec                 float64\n",
       "koi_kepmag          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kepler.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disposition</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>0</td>\n",
       "      <td>8.589871</td>\n",
       "      <td>132.016100</td>\n",
       "      <td>0.765</td>\n",
       "      <td>4.8060</td>\n",
       "      <td>87.7</td>\n",
       "      <td>1.11</td>\n",
       "      <td>929.0</td>\n",
       "      <td>176.40</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5638.0</td>\n",
       "      <td>4.296</td>\n",
       "      <td>1.088</td>\n",
       "      <td>298.74921</td>\n",
       "      <td>46.973351</td>\n",
       "      <td>14.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>0</td>\n",
       "      <td>0.527699</td>\n",
       "      <td>131.705093</td>\n",
       "      <td>1.252</td>\n",
       "      <td>3.2221</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>29.35</td>\n",
       "      <td>2088.0</td>\n",
       "      <td>4500.53</td>\n",
       "      <td>453.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5638.0</td>\n",
       "      <td>4.529</td>\n",
       "      <td>0.903</td>\n",
       "      <td>297.18875</td>\n",
       "      <td>47.093819</td>\n",
       "      <td>14.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9561</th>\n",
       "      <td>1</td>\n",
       "      <td>1.739849</td>\n",
       "      <td>133.001270</td>\n",
       "      <td>0.043</td>\n",
       "      <td>3.1140</td>\n",
       "      <td>48.5</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1608.0</td>\n",
       "      <td>1585.81</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6119.0</td>\n",
       "      <td>4.444</td>\n",
       "      <td>1.031</td>\n",
       "      <td>286.50937</td>\n",
       "      <td>47.163219</td>\n",
       "      <td>14.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9562</th>\n",
       "      <td>0</td>\n",
       "      <td>0.681402</td>\n",
       "      <td>132.181750</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2218.0</td>\n",
       "      <td>5713.41</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6173.0</td>\n",
       "      <td>4.447</td>\n",
       "      <td>1.041</td>\n",
       "      <td>294.16489</td>\n",
       "      <td>47.176281</td>\n",
       "      <td>15.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9563</th>\n",
       "      <td>0</td>\n",
       "      <td>4.856035</td>\n",
       "      <td>135.993300</td>\n",
       "      <td>0.134</td>\n",
       "      <td>3.0780</td>\n",
       "      <td>76.7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1266.0</td>\n",
       "      <td>607.42</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6469.0</td>\n",
       "      <td>4.385</td>\n",
       "      <td>1.193</td>\n",
       "      <td>297.00977</td>\n",
       "      <td>47.121021</td>\n",
       "      <td>14.826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      disposition  koi_period  koi_time0bk  koi_impact  koi_duration  \\\n",
       "9559            0    8.589871   132.016100       0.765        4.8060   \n",
       "9560            0    0.527699   131.705093       1.252        3.2221   \n",
       "9561            1    1.739849   133.001270       0.043        3.1140   \n",
       "9562            0    0.681402   132.181750       0.147        0.8650   \n",
       "9563            0    4.856035   135.993300       0.134        3.0780   \n",
       "\n",
       "      koi_depth  koi_prad  koi_teq  koi_insol  koi_model_snr  \\\n",
       "9559       87.7      1.11    929.0     176.40            8.4   \n",
       "9560     1580.0     29.35   2088.0    4500.53          453.3   \n",
       "9561       48.5      0.72   1608.0    1585.81           10.6   \n",
       "9562      104.0      1.07   2218.0    5713.41           12.3   \n",
       "9563       76.7      1.05   1266.0     607.42            8.2   \n",
       "\n",
       "      koi_tce_plnt_num  koi_steff  koi_slogg  koi_srad         ra        dec  \\\n",
       "9559               1.0     5638.0      4.296     1.088  298.74921  46.973351   \n",
       "9560               1.0     5638.0      4.529     0.903  297.18875  47.093819   \n",
       "9561               1.0     6119.0      4.444     1.031  286.50937  47.163219   \n",
       "9562               1.0     6173.0      4.447     1.041  294.16489  47.176281   \n",
       "9563               1.0     6469.0      4.385     1.193  297.00977  47.121021   \n",
       "\n",
       "      koi_kepmag  \n",
       "9559      14.478  \n",
       "9560      14.082  \n",
       "9561      14.757  \n",
       "9562      15.385  \n",
       "9563      14.826  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kepler.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8945, 16) (8945,)\n"
     ]
    }
   ],
   "source": [
    "# Assign X (data) and y (target)\n",
    "X = kepler.drop(\"disposition\", axis=1)\n",
    "y = kepler[\"disposition\"]\n",
    "print(X.shape, y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>4.370332</td>\n",
       "      <td>131.926960</td>\n",
       "      <td>0.093</td>\n",
       "      <td>2.84500</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.56</td>\n",
       "      <td>1191.0</td>\n",
       "      <td>475.39</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5657.0</td>\n",
       "      <td>4.282</td>\n",
       "      <td>1.182</td>\n",
       "      <td>287.40533</td>\n",
       "      <td>45.918011</td>\n",
       "      <td>15.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>58.873429</td>\n",
       "      <td>153.907600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.48700</td>\n",
       "      <td>226000.0</td>\n",
       "      <td>76.18</td>\n",
       "      <td>679.0</td>\n",
       "      <td>50.35</td>\n",
       "      <td>106.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7078.0</td>\n",
       "      <td>4.192</td>\n",
       "      <td>1.568</td>\n",
       "      <td>295.49011</td>\n",
       "      <td>39.105862</td>\n",
       "      <td>14.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>8.487872</td>\n",
       "      <td>134.495278</td>\n",
       "      <td>0.941</td>\n",
       "      <td>4.19829</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>46.24</td>\n",
       "      <td>798.0</td>\n",
       "      <td>96.00</td>\n",
       "      <td>483.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5553.0</td>\n",
       "      <td>4.558</td>\n",
       "      <td>0.855</td>\n",
       "      <td>280.88580</td>\n",
       "      <td>47.565632</td>\n",
       "      <td>16.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>18.954916</td>\n",
       "      <td>262.466770</td>\n",
       "      <td>1.228</td>\n",
       "      <td>24.24900</td>\n",
       "      <td>868.0</td>\n",
       "      <td>71.39</td>\n",
       "      <td>1139.0</td>\n",
       "      <td>397.48</td>\n",
       "      <td>249.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6362.0</td>\n",
       "      <td>3.761</td>\n",
       "      <td>2.534</td>\n",
       "      <td>284.02679</td>\n",
       "      <td>49.415428</td>\n",
       "      <td>10.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>232.040326</td>\n",
       "      <td>262.253100</td>\n",
       "      <td>0.610</td>\n",
       "      <td>12.23500</td>\n",
       "      <td>291.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>327.0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>15.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5903.0</td>\n",
       "      <td>4.300</td>\n",
       "      <td>1.156</td>\n",
       "      <td>282.06128</td>\n",
       "      <td>47.085491</td>\n",
       "      <td>13.797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_period  koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  \\\n",
       "2178    4.370332   131.926960       0.093       2.84500      178.0      1.56   \n",
       "9054   58.873429   153.907600       0.000      17.48700   226000.0     76.18   \n",
       "5138    8.487872   134.495278       0.941       4.19829   119000.0     46.24   \n",
       "367    18.954916   262.466770       1.228      24.24900      868.0     71.39   \n",
       "8768  232.040326   262.253100       0.610      12.23500      291.0      2.05   \n",
       "\n",
       "      koi_teq  koi_insol  koi_model_snr  koi_tce_plnt_num  koi_steff  \\\n",
       "2178   1191.0     475.39           17.7               1.0     5657.0   \n",
       "9054    679.0      50.35          106.8               1.0     7078.0   \n",
       "5138    798.0      96.00          483.9               1.0     5553.0   \n",
       "367    1139.0     397.48          249.3               1.0     6362.0   \n",
       "8768    327.0       2.71           15.2               3.0     5903.0   \n",
       "\n",
       "      koi_slogg  koi_srad         ra        dec  koi_kepmag  \n",
       "2178      4.282     1.182  287.40533  45.918011      15.133  \n",
       "9054      4.192     1.568  295.49011  39.105862      14.048  \n",
       "5138      4.558     0.855  280.88580  47.565632      16.947  \n",
       "367       3.761     2.534  284.02679  49.415428      10.988  \n",
       "8768      4.300     1.156  282.06128  47.085491      13.797  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>koi_impact</th>\n",
       "      <th>koi_duration</th>\n",
       "      <th>koi_depth</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "      <th>koi_insol</th>\n",
       "      <th>koi_model_snr</th>\n",
       "      <th>koi_tce_plnt_num</th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>43.844397</td>\n",
       "      <td>151.935380</td>\n",
       "      <td>0.852</td>\n",
       "      <td>6.8020</td>\n",
       "      <td>615.0</td>\n",
       "      <td>2.87</td>\n",
       "      <td>531.0</td>\n",
       "      <td>18.77</td>\n",
       "      <td>83.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5854.0</td>\n",
       "      <td>4.406</td>\n",
       "      <td>1.012</td>\n",
       "      <td>300.86398</td>\n",
       "      <td>44.337551</td>\n",
       "      <td>12.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>9.991152</td>\n",
       "      <td>134.393350</td>\n",
       "      <td>0.691</td>\n",
       "      <td>2.6570</td>\n",
       "      <td>392.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>660.0</td>\n",
       "      <td>44.77</td>\n",
       "      <td>16.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4838.0</td>\n",
       "      <td>4.524</td>\n",
       "      <td>0.796</td>\n",
       "      <td>285.17334</td>\n",
       "      <td>48.770039</td>\n",
       "      <td>15.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8382</th>\n",
       "      <td>37.537859</td>\n",
       "      <td>159.736400</td>\n",
       "      <td>0.058</td>\n",
       "      <td>6.5130</td>\n",
       "      <td>269.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>583.0</td>\n",
       "      <td>27.38</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6095.0</td>\n",
       "      <td>4.429</td>\n",
       "      <td>1.082</td>\n",
       "      <td>289.21732</td>\n",
       "      <td>48.204311</td>\n",
       "      <td>15.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>4.180048</td>\n",
       "      <td>173.719249</td>\n",
       "      <td>0.047</td>\n",
       "      <td>2.4479</td>\n",
       "      <td>1770.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>957.0</td>\n",
       "      <td>197.81</td>\n",
       "      <td>124.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5227.0</td>\n",
       "      <td>4.535</td>\n",
       "      <td>0.838</td>\n",
       "      <td>289.78622</td>\n",
       "      <td>46.858791</td>\n",
       "      <td>15.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>4.577974</td>\n",
       "      <td>135.630580</td>\n",
       "      <td>0.343</td>\n",
       "      <td>2.8620</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>259.36</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5795.0</td>\n",
       "      <td>4.554</td>\n",
       "      <td>0.848</td>\n",
       "      <td>297.39319</td>\n",
       "      <td>47.164631</td>\n",
       "      <td>15.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_period  koi_time0bk  koi_impact  koi_duration  koi_depth  koi_prad  \\\n",
       "70     43.844397   151.935380       0.852        6.8020      615.0      2.87   \n",
       "1987    9.991152   134.393350       0.691        2.6570      392.0      1.68   \n",
       "8382   37.537859   159.736400       0.058        6.5130      269.0      1.77   \n",
       "3158    4.180048   173.719249       0.047        2.4479     1770.0      3.44   \n",
       "3207    4.577974   135.630580       0.343        2.8620      125.0      0.96   \n",
       "\n",
       "      koi_teq  koi_insol  koi_model_snr  koi_tce_plnt_num  koi_steff  \\\n",
       "70      531.0      18.77           83.7               2.0     5854.0   \n",
       "1987    660.0      44.77           16.7               2.0     4838.0   \n",
       "8382    583.0      27.38            8.2               1.0     6095.0   \n",
       "3158    957.0     197.81          124.3               2.0     5227.0   \n",
       "3207   1024.0     259.36            9.6               2.0     5795.0   \n",
       "\n",
       "      koi_slogg  koi_srad         ra        dec  koi_kepmag  \n",
       "70        4.406     1.012  300.86398  44.337551      12.882  \n",
       "1987      4.524     0.796  285.17334  48.770039      15.311  \n",
       "8382      4.429     1.082  289.21732  48.204311      15.769  \n",
       "3158      4.535     0.838  289.78622  46.858791      15.342  \n",
       "3207      4.554     0.848  297.39319  47.164631      15.302  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the data using MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesdietz/anaconda3/envs/PythonWebMongo/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7558139534883721\n",
      "Testing Data Score: 0.7729101475189987\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 Predictions:   [1 1 1 1 1 1 1 1 1 1]\n",
      "First 10 Actual labels: [1, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test_scaled)\n",
    "print(f\"First 10 Predictions:   {predictions[:10]}\")\n",
    "print(f\"First 10 Actual labels: {y_test[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2208</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2216</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2225</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2237 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prediction  Actual\n",
       "0              1       1\n",
       "1              1       1\n",
       "2              1       0\n",
       "3              1       1\n",
       "4              1       1\n",
       "5              1       1\n",
       "6              1       0\n",
       "7              1       1\n",
       "8              1       1\n",
       "9              1       1\n",
       "10             1       1\n",
       "11             0       0\n",
       "12             1       1\n",
       "13             0       0\n",
       "14             1       1\n",
       "15             1       1\n",
       "16             0       1\n",
       "17             1       0\n",
       "18             1       1\n",
       "19             1       0\n",
       "20             0       0\n",
       "21             1       1\n",
       "22             0       0\n",
       "23             1       0\n",
       "24             0       0\n",
       "25             0       0\n",
       "26             1       1\n",
       "27             1       1\n",
       "28             0       1\n",
       "29             0       0\n",
       "...          ...     ...\n",
       "2207           1       1\n",
       "2208           0       0\n",
       "2209           1       1\n",
       "2210           0       0\n",
       "2211           1       0\n",
       "2212           1       1\n",
       "2213           1       0\n",
       "2214           1       1\n",
       "2215           1       0\n",
       "2216           0       0\n",
       "2217           1       1\n",
       "2218           0       0\n",
       "2219           1       1\n",
       "2220           0       0\n",
       "2221           0       0\n",
       "2222           0       0\n",
       "2223           1       1\n",
       "2224           1       1\n",
       "2225           1       1\n",
       "2226           0       0\n",
       "2227           1       1\n",
       "2228           1       0\n",
       "2229           1       0\n",
       "2230           1       1\n",
       "2231           0       0\n",
       "2232           0       1\n",
       "2233           1       1\n",
       "2234           1       1\n",
       "2235           1       1\n",
       "2236           0       0\n",
       "\n",
       "[2237 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the SVC Model\n",
    "from sklearn.svm import SVC\n",
    "svclassifier = SVC(kernel='linear')\n",
    "svclassifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7579010137149672\n",
      "Testing Data Score: 0.7796155565489495\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {svclassifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {svclassifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 5, 10], 'gamma': [0.001, 0.005, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.001, .005, 0.01]}\n",
    "grid = GridSearchCV(svclassifier, param_grid, verbose=3)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesdietz/anaconda3/envs/PythonWebMongo/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ....... C=1, gamma=0.001, score=0.7522361359570662, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=1, gamma=0.001, score=0.7504472271914132, total=   0.3s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=1, gamma=0.001, score=0.7455277280858676, total=   0.3s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] ....... C=1, gamma=0.005, score=0.7522361359570662, total=   0.3s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] ....... C=1, gamma=0.005, score=0.7504472271914132, total=   0.3s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] ....... C=1, gamma=0.005, score=0.7455277280858676, total=   0.3s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7522361359570662, total=   0.3s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7504472271914132, total=   0.3s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ........ C=1, gamma=0.01, score=0.7455277280858676, total=   0.4s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] ....... C=5, gamma=0.001, score=0.7598389982110912, total=   0.3s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] ....... C=5, gamma=0.001, score=0.7647584973166368, total=   0.3s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] ....... C=5, gamma=0.001, score=0.7535778175313059, total=   0.3s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] ....... C=5, gamma=0.005, score=0.7598389982110912, total=   0.3s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] ....... C=5, gamma=0.005, score=0.7647584973166368, total=   0.4s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] ....... C=5, gamma=0.005, score=0.7535778175313059, total=   0.3s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ........ C=5, gamma=0.01, score=0.7598389982110912, total=   0.3s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ........ C=5, gamma=0.01, score=0.7647584973166368, total=   0.3s\n",
      "[CV] C=5, gamma=0.01 .................................................\n",
      "[CV] ........ C=5, gamma=0.01, score=0.7535778175313059, total=   0.3s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ....... C=10, gamma=0.001, score=0.768783542039356, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.7723613595706619, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ...... C=10, gamma=0.001, score=0.7598389982110912, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ....... C=10, gamma=0.005, score=0.768783542039356, total=   0.3s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ...... C=10, gamma=0.005, score=0.7723613595706619, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ...... C=10, gamma=0.005, score=0.7598389982110912, total=   0.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ........ C=10, gamma=0.01, score=0.768783542039356, total=   0.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.7723613595706619, total=   0.4s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ....... C=10, gamma=0.01, score=0.7598389982110912, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:   13.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [1, 5, 10], 'gamma': [0.001, 0.005, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the grid search estimator. \n",
    "# This will take the SVC model and try each combination of parameters\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001}\n",
      "0.766994633273703\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.703\n",
      "k: 3, Train/Test Score: 0.848/0.730\n",
      "k: 5, Train/Test Score: 0.810/0.730\n",
      "k: 7, Train/Test Score: 0.792/0.728\n",
      "k: 9, Train/Test Score: 0.783/0.722\n",
      "k: 11, Train/Test Score: 0.778/0.732\n",
      "k: 13, Train/Test Score: 0.769/0.731\n",
      "k: 15, Train/Test Score: 0.767/0.737\n",
      "k: 17, Train/Test Score: 0.761/0.731\n",
      "k: 19, Train/Test Score: 0.759/0.731\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=9 Test Acc: 0.737\n"
     ]
    }
   ],
   "source": [
    "# Note that k: 15 or even 11 provides the best accuracy where the classifier starts to stablize but none very good, may be k = 15 slightly better\n",
    "knn = KNeighborsClassifier(n_neighbors=15)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=9 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NETWORK, DEEP LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.2-tf'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow\n",
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=16))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               1700      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 12,002\n",
      "Trainable params: 12,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      " - 0s - loss: 0.6046 - acc: 0.6603\n",
      "Epoch 2/60\n",
      " - 0s - loss: 0.5345 - acc: 0.7391\n",
      "Epoch 3/60\n",
      " - 0s - loss: 0.5188 - acc: 0.7497\n",
      "Epoch 4/60\n",
      " - 0s - loss: 0.4966 - acc: 0.7716\n",
      "Epoch 5/60\n",
      " - 0s - loss: 0.4905 - acc: 0.7753\n",
      "Epoch 6/60\n",
      " - 0s - loss: 0.4829 - acc: 0.7770\n",
      "Epoch 7/60\n",
      " - 0s - loss: 0.4753 - acc: 0.7837\n",
      "Epoch 8/60\n",
      " - 0s - loss: 0.4698 - acc: 0.7835\n",
      "Epoch 9/60\n",
      " - 0s - loss: 0.4644 - acc: 0.7831\n",
      "Epoch 10/60\n",
      " - 0s - loss: 0.4648 - acc: 0.7841\n",
      "Epoch 11/60\n",
      " - 0s - loss: 0.4568 - acc: 0.7911\n",
      "Epoch 12/60\n",
      " - 0s - loss: 0.4550 - acc: 0.7934\n",
      "Epoch 13/60\n",
      " - 0s - loss: 0.4521 - acc: 0.7892\n",
      "Epoch 14/60\n",
      " - 0s - loss: 0.4458 - acc: 0.7931\n",
      "Epoch 15/60\n",
      " - 0s - loss: 0.4451 - acc: 0.7962\n",
      "Epoch 16/60\n",
      " - 0s - loss: 0.4422 - acc: 0.7992\n",
      "Epoch 17/60\n",
      " - 0s - loss: 0.4384 - acc: 0.8007\n",
      "Epoch 18/60\n",
      " - 0s - loss: 0.4401 - acc: 0.7999\n",
      "Epoch 19/60\n",
      " - 0s - loss: 0.4403 - acc: 0.7990\n",
      "Epoch 20/60\n",
      " - 0s - loss: 0.4314 - acc: 0.8032\n",
      "Epoch 21/60\n",
      " - 0s - loss: 0.4305 - acc: 0.8064\n",
      "Epoch 22/60\n",
      " - 0s - loss: 0.4276 - acc: 0.8077\n",
      "Epoch 23/60\n",
      " - 0s - loss: 0.4274 - acc: 0.8080\n",
      "Epoch 24/60\n",
      " - 0s - loss: 0.4236 - acc: 0.8061\n",
      "Epoch 25/60\n",
      " - 0s - loss: 0.4242 - acc: 0.8080\n",
      "Epoch 26/60\n",
      " - 0s - loss: 0.4175 - acc: 0.8078\n",
      "Epoch 27/60\n",
      " - 0s - loss: 0.4197 - acc: 0.8078\n",
      "Epoch 28/60\n",
      " - 0s - loss: 0.4184 - acc: 0.8108\n",
      "Epoch 29/60\n",
      " - 0s - loss: 0.4184 - acc: 0.8114\n",
      "Epoch 30/60\n",
      " - 0s - loss: 0.4146 - acc: 0.8131\n",
      "Epoch 31/60\n",
      " - 0s - loss: 0.4107 - acc: 0.8162\n",
      "Epoch 32/60\n",
      " - 0s - loss: 0.4090 - acc: 0.8165\n",
      "Epoch 33/60\n",
      " - 0s - loss: 0.4121 - acc: 0.8144\n",
      "Epoch 34/60\n",
      " - 0s - loss: 0.4071 - acc: 0.8187\n",
      "Epoch 35/60\n",
      " - 0s - loss: 0.4060 - acc: 0.8202\n",
      "Epoch 36/60\n",
      " - 0s - loss: 0.4024 - acc: 0.8180\n",
      "Epoch 37/60\n",
      " - 0s - loss: 0.4041 - acc: 0.8196\n",
      "Epoch 38/60\n",
      " - 0s - loss: 0.4053 - acc: 0.8196\n",
      "Epoch 39/60\n",
      " - 0s - loss: 0.4004 - acc: 0.8202\n",
      "Epoch 40/60\n",
      " - 0s - loss: 0.3997 - acc: 0.8187\n",
      "Epoch 41/60\n",
      " - 0s - loss: 0.3980 - acc: 0.8253\n",
      "Epoch 42/60\n",
      " - 0s - loss: 0.3947 - acc: 0.8230\n",
      "Epoch 43/60\n",
      " - 0s - loss: 0.3960 - acc: 0.8227\n",
      "Epoch 44/60\n",
      " - 0s - loss: 0.3992 - acc: 0.8217\n",
      "Epoch 45/60\n",
      " - 0s - loss: 0.3924 - acc: 0.8299\n",
      "Epoch 46/60\n",
      " - 0s - loss: 0.3939 - acc: 0.8260\n",
      "Epoch 47/60\n",
      " - 0s - loss: 0.3921 - acc: 0.8266\n",
      "Epoch 48/60\n",
      " - 0s - loss: 0.3929 - acc: 0.8235\n",
      "Epoch 49/60\n",
      " - 0s - loss: 0.3932 - acc: 0.8219\n",
      "Epoch 50/60\n",
      " - 0s - loss: 0.3870 - acc: 0.8289\n",
      "Epoch 51/60\n",
      " - 0s - loss: 0.3881 - acc: 0.8269\n",
      "Epoch 52/60\n",
      " - 0s - loss: 0.3871 - acc: 0.8251\n",
      "Epoch 53/60\n",
      " - 0s - loss: 0.3850 - acc: 0.8290\n",
      "Epoch 54/60\n",
      " - 0s - loss: 0.3831 - acc: 0.8308\n",
      "Epoch 55/60\n",
      " - 0s - loss: 0.3824 - acc: 0.8330\n",
      "Epoch 56/60\n",
      " - 0s - loss: 0.3809 - acc: 0.8283\n",
      "Epoch 57/60\n",
      " - 0s - loss: 0.3838 - acc: 0.8311\n",
      "Epoch 58/60\n",
      " - 0s - loss: 0.3817 - acc: 0.8286\n",
      "Epoch 59/60\n",
      " - 0s - loss: 0.3785 - acc: 0.8318\n",
      "Epoch 60/60\n",
      " - 0s - loss: 0.3783 - acc: 0.8344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8b4258af98>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Neural Network - Loss: 0.39168435724174866, Accuracy: 0.836835047284247\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_predictions = model.predict_classes(X_test_scaled[:5])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [1 1 1 1 1]\n",
      "Actual Labels: [1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCUSSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Exoplanetary data originating from NASA were imported and preprocessed which involved creating a matrix of X values \n",
    "and a y value which were then split into training and testing sets.\n",
    "\n",
    "(2) Data were then scaled using the MinMax scaler which projected them into a zero to 1 space.\n",
    "\n",
    "(3) Scaled data were then used to train and test four machine learning models--(a) Logistic Regression, (b) Support Vector \n",
    "Machine classifier, (c) K Nearest Neighbors, and (d) a Neural Network Deep Learning Model.\n",
    "\n",
    "(4) The Logistic Regression Model demonstrated a Training Data Score of 0.756 compared with a Testing Data Score\n",
    "of 0.773.  The SVM/SVC Model initially yielded an accuracy score of 0.758 with the Training Data compared to a \n",
    "0.780 with Testing Data.  The hyperparameters of the model were then fine-tuned with a GridSearch method which yielded a set of parameters (C=10, gamma=0.001) and a revised accuracy score.  A KNN model was tested which yielded an accuracy score of 0.737 with 10 neighbors used for classification.  Finally, a Neural Network Deep Learning Model was run with two hidden layers of 100 nodes each.  This model was, by far, the best model in terms of prediction using the testing data. It yielded an accuracy of 0.837 suggesting it was over 83 percent accurate in its prediction of whether the object was a false positive or an exoplanet candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
